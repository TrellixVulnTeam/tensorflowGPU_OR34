{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    " \n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -------------- constant variable setting (change according to your system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = '/home/vinamra/myproj/raccoon_dataset/models/research/training/output_inference_graph.pb'\n",
    "\n",
    "PATH_TO_LABELS = '/home/vinamra/myproj/raccoon_dataset/models/research/training/object-detection.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we do not need to download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###download model file online\n",
    "# opener = urllib.request.URLopener()\n",
    "# opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "# tar_file = tarfile.open(MODEL_FILE)\n",
    "# for file in tar_file.getmembers():\n",
    "#     file_name = os.path.basename(file.name)\n",
    "#     if 'frozen_inference_graph.pb' in file_name:\n",
    "#         tar_file.extract(file, os.getcwd())\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get labels working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The path to the images for the testing purpose is defined here. Here we have a naming convention “image[i]” for i in (1 to n+1), n being the number of images provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = '/home/vinamra/myproj/raccoon_dataset/testimg'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'raccoon-{}.jpg'.format(i)) for i in range(1, 8) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Our Final loop, which will call all the functions defined above and will run the inference on all the input images one by one, which will provide us the output of images in which objects are detected with labels and the percentage/score of that object being similar to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_path in TEST_IMAGE_PATHS:\n",
    "#   image = Image.open(image_path)\n",
    "#   # the array based representation of the image will be used later in order to prepare the\n",
    "#   # result image with boxes and labels on it.\n",
    "#   image_np = load_image_into_numpy_array(image)\n",
    "#   # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "#   image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#   # Actual detection.\n",
    "#   output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "#   # Visualization of the results of a detection.\n",
    "#   vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#       image_np,\n",
    "#       output_dict['detection_boxes'],\n",
    "#       output_dict['detection_classes'],\n",
    "#       output_dict['detection_scores'],\n",
    "#       category_index,\n",
    "#       instance_masks=output_dict.get('detection_masks'),\n",
    "#       use_normalized_coordinates=True,\n",
    "#       line_thickness=8)\n",
    "# plt.figure(figsize=IMAGE_SIZE)\n",
    "# plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_detections': 100, 'detection_boxes': array([[2.15123922e-01, 1.14053577e-01, 9.83867526e-01, 7.88877249e-01],\n",
      "       [0.00000000e+00, 7.41600037e-01, 1.00000000e+00, 1.00000000e+00],\n",
      "       [1.45687863e-01, 4.97366488e-01, 4.24482465e-01, 1.00000000e+00],\n",
      "       [3.62976104e-01, 4.63679373e-01, 6.27409935e-01, 1.00000000e+00],\n",
      "       [7.90205240e-01, 9.66072530e-02, 9.44084048e-01, 4.03132856e-01],\n",
      "       [3.54617834e-04, 8.34154487e-02, 2.09806919e-01, 1.00000000e+00],\n",
      "       [8.63081574e-01, 6.41127467e-01, 9.92976427e-01, 9.22261119e-01],\n",
      "       [1.28098726e-02, 5.25536776e-01, 9.96310353e-01, 9.75444674e-01],\n",
      "       [2.38350302e-01, 1.20674640e-01, 9.14407015e-01, 4.11449581e-01],\n",
      "       [1.15581155e-02, 1.67183168e-02, 1.00000000e+00, 9.18781310e-02],\n",
      "       [4.14118171e-03, 6.46384954e-01, 7.88325548e-01, 8.99088144e-01],\n",
      "       [3.22317243e-01, 7.06262112e-01, 5.60698092e-01, 1.00000000e+00],\n",
      "       [6.24355972e-02, 4.61865664e-02, 5.75228095e-01, 9.45956230e-01],\n",
      "       [0.00000000e+00, 7.19686747e-01, 5.07166862e-01, 1.00000000e+00],\n",
      "       [8.56389940e-01, 9.91975367e-02, 9.86773670e-01, 3.93844187e-01],\n",
      "       [4.74790275e-01, 3.62097025e-02, 9.70648348e-01, 8.73755753e-01],\n",
      "       [2.76792645e-01, 0.00000000e+00, 8.39900374e-01, 1.00000000e+00],\n",
      "       [8.48329067e-03, 0.00000000e+00, 2.33669579e-01, 5.22226691e-01],\n",
      "       [3.07296038e-01, 2.98921764e-01, 7.13584423e-01, 1.00000000e+00],\n",
      "       [0.00000000e+00, 6.74821019e-01, 1.02081031e-01, 1.00000000e+00],\n",
      "       [1.49659738e-02, 6.95762098e-01, 2.44116694e-01, 1.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 4.69997257e-01, 6.01295978e-02],\n",
      "       [5.10360837e-01, 6.06773496e-01, 1.00000000e+00, 1.00000000e+00],\n",
      "       [0.00000000e+00, 7.43186951e-01, 4.20708835e-01, 8.76868963e-01],\n",
      "       [0.00000000e+00, 5.34394085e-01, 5.01688182e-01, 8.93185556e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 5.18222511e-01, 2.57033110e-01],\n",
      "       [7.17264831e-01, 5.30293107e-01, 9.73061502e-01, 1.00000000e+00],\n",
      "       [6.34982288e-01, 6.02641255e-02, 7.92431176e-01, 3.46557081e-01],\n",
      "       [2.38163471e-01, 6.51532412e-01, 4.33521271e-01, 1.00000000e+00],\n",
      "       [1.12774819e-01, 5.32360911e-01, 7.05499411e-01, 7.85614967e-01],\n",
      "       [3.57919514e-01, 6.06731415e-01, 5.36368549e-01, 1.00000000e+00],\n",
      "       [4.68072295e-03, 3.67340535e-01, 7.55747557e-01, 1.00000000e+00],\n",
      "       [0.00000000e+00, 4.65285927e-02, 9.73221138e-02, 4.50120866e-01],\n",
      "       [0.00000000e+00, 8.07904482e-01, 2.44569361e-01, 9.22052503e-01],\n",
      "       [8.57151389e-01, 5.48878431e-01, 9.98464942e-01, 1.00000000e+00],\n",
      "       [2.18553036e-01, 3.72260600e-01, 5.20713329e-01, 8.53428245e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 3.00071597e-01, 7.73065090e-01],\n",
      "       [5.47217250e-01, 4.14546758e-01, 8.60639334e-01, 1.00000000e+00],\n",
      "       [6.08348370e-01, 5.01693189e-02, 9.15494561e-01, 9.20377731e-01],\n",
      "       [6.89795613e-01, 1.62680045e-01, 1.00000000e+00, 3.14952612e-01],\n",
      "       [5.21244109e-03, 4.21480656e-01, 2.35887125e-01, 1.00000000e+00],\n",
      "       [3.95500541e-01, 1.84675470e-01, 5.07716060e-01, 2.89178401e-01],\n",
      "       [7.54681230e-03, 8.47541869e-01, 9.82885838e-01, 9.88614142e-01],\n",
      "       [2.95680225e-01, 4.38745201e-01, 5.62764883e-01, 9.94309127e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 8.80272865e-01, 2.28587925e-01],\n",
      "       [0.00000000e+00, 5.68927824e-01, 3.14729452e-01, 1.00000000e+00],\n",
      "       [0.00000000e+00, 4.42092866e-02, 5.10530770e-01, 4.77655649e-01],\n",
      "       [0.00000000e+00, 7.08224714e-01, 2.61550158e-01, 8.28623593e-01],\n",
      "       [0.00000000e+00, 7.57055402e-01, 2.68449038e-01, 8.72235537e-01],\n",
      "       [0.00000000e+00, 3.53346586e-01, 4.57821488e-01, 9.50869083e-01],\n",
      "       [1.09222487e-01, 0.00000000e+00, 3.48302603e-01, 5.43199062e-01],\n",
      "       [8.33682716e-01, 0.00000000e+00, 9.92170036e-01, 4.28376824e-01],\n",
      "       [1.12997472e-01, 1.84174955e-01, 4.38726068e-01, 1.00000000e+00],\n",
      "       [6.57953739e-01, 1.26608118e-01, 7.68477082e-01, 2.38475844e-01],\n",
      "       [7.21744061e-01, 0.00000000e+00, 9.85430002e-01, 9.17878866e-01],\n",
      "       [8.70465159e-01, 5.14040112e-01, 9.85753179e-01, 8.24160814e-01],\n",
      "       [6.60122514e-01, 1.76905185e-01, 7.66497135e-01, 2.93269008e-01],\n",
      "       [3.60001206e-01, 6.84561074e-01, 9.57162976e-01, 1.00000000e+00],\n",
      "       [1.98761225e-02, 8.23548853e-01, 6.65502667e-01, 1.00000000e+00],\n",
      "       [3.88795435e-02, 1.38246119e-02, 8.51506114e-01, 6.86935186e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 6.65660262e-01, 4.70886081e-02],\n",
      "       [1.87510878e-01, 5.22793472e-01, 7.64689803e-01, 9.44028795e-01],\n",
      "       [0.00000000e+00, 7.45909095e-01, 3.16608489e-01, 9.60791588e-01],\n",
      "       [8.60678315e-01, 0.00000000e+00, 9.86578584e-01, 3.13165545e-01],\n",
      "       [0.00000000e+00, 6.37068450e-01, 1.61841661e-01, 9.93911445e-01],\n",
      "       [3.83380473e-01, 7.78754205e-02, 5.34495354e-01, 3.95955920e-01],\n",
      "       [6.41388893e-01, 6.63745642e-01, 9.77250695e-01, 9.94907498e-01],\n",
      "       [7.34138846e-01, 2.24899650e-02, 9.90814209e-01, 3.22176844e-01],\n",
      "       [6.09998167e-01, 1.77408665e-01, 7.11309850e-01, 2.95132548e-01],\n",
      "       [8.81576300e-01, 7.23697305e-01, 9.94363427e-01, 1.00000000e+00],\n",
      "       [5.61561763e-01, 1.19807914e-01, 9.31187212e-01, 2.66470373e-01],\n",
      "       [5.61667234e-03, 0.00000000e+00, 1.50124222e-01, 2.73859382e-01],\n",
      "       [6.67267203e-01, 6.18201017e-01, 8.30984116e-01, 1.00000000e+00],\n",
      "       [2.83372045e-01, 1.77123383e-01, 6.56748176e-01, 3.00134718e-01],\n",
      "       [3.90475690e-02, 6.79075599e-01, 7.37882853e-01, 1.00000000e+00],\n",
      "       [5.71627915e-03, 5.03358841e-01, 1.17581837e-01, 1.00000000e+00],\n",
      "       [6.16742551e-01, 5.37265658e-01, 8.77665579e-01, 1.00000000e+00],\n",
      "       [5.12717903e-01, 5.59286118e-01, 7.61857212e-01, 1.00000000e+00],\n",
      "       [7.43593335e-01, 1.30580217e-01, 8.96666408e-01, 4.58325714e-01],\n",
      "       [2.23083675e-01, 4.73609686e-01, 7.99012005e-01, 7.75791049e-01],\n",
      "       [1.03347361e-01, 6.30025119e-02, 6.78074896e-01, 5.02338588e-01],\n",
      "       [0.00000000e+00, 8.55842352e-01, 2.45507360e-01, 9.75134373e-01],\n",
      "       [2.85384357e-01, 0.00000000e+00, 5.86217940e-01, 5.78615785e-01],\n",
      "       [0.00000000e+00, 8.08595657e-01, 8.14653933e-02, 9.33652997e-01],\n",
      "       [3.43246162e-01, 1.85087964e-01, 4.52999532e-01, 2.89716303e-01],\n",
      "       [2.51637459e-01, 7.64416516e-01, 6.81982815e-01, 8.79803002e-01],\n",
      "       [3.69490266e-01, 8.55356753e-02, 7.16875196e-01, 8.51510644e-01],\n",
      "       [1.26031756e-01, 0.00000000e+00, 2.63021827e-01, 1.94606617e-01],\n",
      "       [5.27323902e-01, 0.00000000e+00, 7.76400149e-01, 5.92895627e-01],\n",
      "       [7.63592720e-01, 7.51197159e-01, 1.00000000e+00, 8.87798011e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 6.90097570e-01, 3.85872900e-01],\n",
      "       [2.21135944e-01, 4.14643437e-05, 8.35860610e-01, 5.54603487e-02],\n",
      "       [7.64546931e-01, 6.98559821e-01, 1.00000000e+00, 8.43625247e-01],\n",
      "       [1.30124748e-01, 6.95703089e-01, 3.38036925e-01, 1.00000000e+00],\n",
      "       [6.92578554e-01, 1.28364086e-01, 1.00000000e+00, 2.70630240e-01],\n",
      "       [4.92791831e-03, 7.03182995e-01, 4.74060118e-01, 8.35365832e-01],\n",
      "       [7.38909543e-02, 9.22573090e-01, 1.97359711e-01, 1.00000000e+00],\n",
      "       [0.00000000e+00, 2.26853818e-01, 1.02014996e-01, 5.85680962e-01],\n",
      "       [8.09677482e-01, 0.00000000e+00, 9.37064767e-01, 2.60433406e-01],\n",
      "       [6.20422900e-01, 0.00000000e+00, 1.00000000e+00, 6.39209375e-02]],\n",
      "      dtype=float32), 'detection_scores': array([9.9990773e-01, 5.8897607e-02, 1.2573261e-03, 1.0033887e-03,\n",
      "       9.5165032e-04, 8.9738722e-04, 8.7164051e-04, 8.4409845e-04,\n",
      "       7.0746092e-04, 5.9826899e-04, 5.0255703e-04, 4.9134495e-04,\n",
      "       4.8530495e-04, 4.4263704e-04, 4.3440869e-04, 4.2468897e-04,\n",
      "       4.1535022e-04, 3.9504725e-04, 3.9288751e-04, 3.8961391e-04,\n",
      "       3.8695088e-04, 3.8406067e-04, 3.7410308e-04, 3.7219480e-04,\n",
      "       3.7071266e-04, 3.6657855e-04, 3.6285858e-04, 3.5978464e-04,\n",
      "       3.5434461e-04, 3.5358101e-04, 3.4995080e-04, 3.4537504e-04,\n",
      "       3.3808351e-04, 3.3587293e-04, 3.3300783e-04, 3.2683654e-04,\n",
      "       3.2362060e-04, 3.2340625e-04, 3.1681787e-04, 3.1638503e-04,\n",
      "       3.1197749e-04, 2.9751222e-04, 2.9431528e-04, 2.8984292e-04,\n",
      "       2.8839713e-04, 2.8359040e-04, 2.7431524e-04, 2.7125419e-04,\n",
      "       2.6857885e-04, 2.6595072e-04, 2.5827889e-04, 2.5580393e-04,\n",
      "       2.4989806e-04, 2.4760631e-04, 2.4440148e-04, 2.4398726e-04,\n",
      "       2.3522126e-04, 2.3193064e-04, 2.3081616e-04, 2.2251331e-04,\n",
      "       2.1964069e-04, 2.1812618e-04, 2.1568232e-04, 2.1355214e-04,\n",
      "       2.1116815e-04, 2.0984908e-04, 2.0707813e-04, 2.0580734e-04,\n",
      "       2.0451589e-04, 2.0401826e-04, 2.0378496e-04, 2.0004265e-04,\n",
      "       1.9848433e-04, 1.9814301e-04, 1.9806594e-04, 1.9707826e-04,\n",
      "       1.9691428e-04, 1.9569746e-04, 1.9522799e-04, 1.9466718e-04,\n",
      "       1.9201940e-04, 1.8854847e-04, 1.8748878e-04, 1.8192321e-04,\n",
      "       1.7870257e-04, 1.7838675e-04, 1.7639647e-04, 1.7617106e-04,\n",
      "       1.7590738e-04, 1.7539655e-04, 1.7471249e-04, 1.7456763e-04,\n",
      "       1.7339230e-04, 1.7325298e-04, 1.7168086e-04, 1.6405353e-04,\n",
      "       1.6248118e-04, 1.6164087e-04, 1.6110294e-04, 1.6024208e-04],\n",
      "      dtype=float32), 'detection_classes': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint8)}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'category_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0409a3ee10a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mcategory_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0minstance_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'detection_masks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0muse_normalized_coordinates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'category_index' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "  image = Image.open(image_path)\n",
    "  # the array based representation of the image will be used later in order to prepare the\n",
    "  # result image with boxes and labels on it.\n",
    "  image_np = load_image_into_numpy_array(image)\n",
    "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "  # Actual detection.\n",
    "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "  print(output_dict)\n",
    "  # Visualization of the results of a detection.\n",
    "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "  plt.figure(figsize=IMAGE_SIZE)\n",
    "  plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
